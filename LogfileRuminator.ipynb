{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the paragraph about the microCT-scanning from logfiles of the scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas\n",
    "import glob\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "if 'Linux' in platform.system():\n",
    "    BasePath = os.path.join(os.path.sep, 'home', 'habi', 'P')\n",
    "elif 'Windows' in platform.system():\n",
    "    BasePath = os.path.join('P:', os.sep)\n",
    "# Use *this* folder for the bone microvasculature manuscript\n",
    "Root = os.path.join(BasePath, 'Documents', 'Publications', 'Ruslan Bone', 'manubot', 'content', 'data')\n",
    "print('We are loading all the data from the folder %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "# Using os.walk is way faster than using recursive glob.glob, see DataWrangling.ipynb for details\n",
    "# Not sorting the found logfiles is also making it quicker\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('We found a total of %s log files in %s' % (len(Data), Root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude all substack log files\n",
    "# They end in \"~01.log\", \"~02.log\", etc\n",
    "# A simple regex searching for \"~ digit digit\" helps us to drop those\n",
    "regex = r\"~\\d\\d\"\n",
    "for c, row in Data.iterrows():\n",
    "    if re.search(regex, row.LogFile):\n",
    "        # print(row.LogFile)\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe index\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Excluding subscan log files, we now have %s log files' % len(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data from all the log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Scanner'] = [scanner(log) for log in Data['LogFile']]\n",
    "Data['ControlSoftware'] = [str(controlsoftware(log)) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voxelsize'] = [pixelsize(log) for log in Data['LogFile']]\n",
    "Data['Voxelsize_rounded'] = [pixelsize(log,rounded=True) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Source'] = [source(log) for log in Data['LogFile']]\n",
    "Data['Camera'] = [camera(log) for log in Data['LogFile']]\n",
    "Data['Exposure'] = [exposuretime(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [averaging(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voltage'] = [voltage(log) for log in Data['LogFile']]\n",
    "Data['Current'] = [current(log) for log in Data['LogFile']]\n",
    "Data['Filter'] = [whichfilter(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Stacks'] = [stacks(log) for log in Data['LogFile']]\n",
    "Data['NumProj'] = [numproj(log) for log in Data['LogFile']]\n",
    "Data['ProjSize'] = [projection_size(log) for log in Data['LogFile']]\n",
    "Data['ThreeSixty'] = [threesixtyscan(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [rotationstep(log) for log in Data['LogFile']]\n",
    "Data['Wide'] = [overlapscan(log) for log in Data.LogFile]\n",
    "Data['Duration'] = [duration(log) for log in Data['LogFile']]\n",
    "Data['Date'] = [scandate(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['NRecon'] = [nreconversion(log)[1] for log in Data['LogFile']]\n",
    "Data['RingRemoval'] = [ringremoval(log) for log in Data['LogFile']]\n",
    "Data['Beamhardening'] = [beamhardening(log) for log in Data['LogFile']]\n",
    "Data['DefectPixelMasking'] = [defectpixelmasking(log) for log in Data['LogFile']]\n",
    "Data['GrayValue'] = [reconstruction_grayvalue(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['RecSize'] = [reconstruction_size(log) for log in Data['LogFile']]\n",
    "Data['ROI'] = [region_of_interest(log, verbose=False) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Duration'] = [duration(log) for log in Data['LogFile']]\n",
    "Data['Date'] = [scandate(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we loaded the data, we customize the standard log file parser notebook for the microvasculature manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folder name\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample name to then match to figure number\n",
    "# We bluntly split the path at the `os.path.sep` and user the first item of this separated list\n",
    "Data['Sample'] = [(foldername[len(Root)+1:]).split(os.path.sep)[0] for foldername in Data['Folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_figure(samplename):\n",
    "    figurenumber = None\n",
    "    if 'Israel' in samplename:\n",
    "        figurenumber = 1\n",
    "    elif '11O' in samplename:\n",
    "        # Some are named 11OKT, some 11Okt\n",
    "        figurenumber = 2\n",
    "    elif 'c1m5' in samplename:\n",
    "        figurenumber = 3\n",
    "    elif '0_99' in samplename:\n",
    "        figurenumber = 4    \n",
    "    elif 'Vreni' in samplename:\n",
    "        figurenumber = 5\n",
    "    elif '_sample4' in samplename:\n",
    "        figurenumber = 6\n",
    "    elif 'Mouse_1EAR' in samplename:\n",
    "        figurenumber = 7\n",
    "    return(int(figurenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sample names to our figures \n",
    "Data['Figure'] = [match_to_figure(s) for s in Data['Sample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by figure number\n",
    "Data.sort_values(by=['Figure', 'Sample'], inplace=True)\n",
    "# Reset dataframe index\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cull irrelevant beginning of path from logfile\n",
    "Data['LogFile'] = [lf[len(Root)+1:] for lf in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cull irrelevant beginning of path from logfile\n",
    "Data['Folder'] = [folder.split('data')[1] for folder in Data['Folder']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add data on animals to the table, since one reviewer specifically asked us to\n",
    "\n",
    "> insert a descriptive table of each animal model studied, reporting strain, age, number, sex,\n",
    "> model of the tomograph used to study it, pixel size, Energy, current, etc.\n",
    "\n",
    "(the tomography data was already present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set most generally used values\n",
    "Data['Animal'] = 'Mouse'\n",
    "Data['Strain'] = 'CB17SCID'\n",
    "Data['Age'] = '10 weeks'\n",
    "Data['Sex'] = 'm'\n",
    "Data['N'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mice from Israel are different\n",
    "Data.loc[Data['LogFile'].str.contains('Israel'), 'Strain'] = 'BALB/cOlaHsd and C57BL/6J crossing'\n",
    "Data.loc[Data['LogFile'].str.contains('Israel'), 'Age'] = '21 months'\n",
    "Data.loc[Data['LogFile'].str.contains('Israel'), 'N'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mice from the dental experiment are different\n",
    "Data.loc[Data['LogFile'].str.contains('_kiefer'), 'Strain'] = 'C57BL/6'\n",
    "Data.loc[Data['LogFile'].str.contains('_kiefer'), 'Age'] = '12 weeks'\n",
    "Data.loc[Data['LogFile'].str.contains('_kiefer'), 'N'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vreni is a Göttingen minipig\n",
    "Data.loc[Data['LogFile'].str.contains('Vreni'), 'Animal'] = 'Minipig'\n",
    "Data.loc[Data['LogFile'].str.contains('Vreni'), 'Strain'] = 'Göttingen'\n",
    "Data.loc[Data['LogFile'].str.contains('Vreni'), 'Age'] = '30 months'  # Aproximation, we haven't heard back from Petr\n",
    "Data.loc[Data['LogFile'].str.contains('Vreni'), 'Sex'] = 'f'\n",
    "Data.loc[Data['LogFile'].str.contains('Vreni'), 'N'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Straumann minipigs are also from Göttingen minipig\n",
    "Data.loc[Data['LogFile'].str.contains('sample4'), 'Animal'] = 'Minipig'\n",
    "Data.loc[Data['LogFile'].str.contains('sample4'), 'Strain'] = 'Göttingen'\n",
    "Data.loc[Data['LogFile'].str.contains('sample4'), 'Age'] = '30 months'  # We were told that their age was 28-32 months\n",
    "Data.loc[Data['LogFile'].str.contains('sample4'), 'Sex'] = 'f'\n",
    "Data.loc[Data['LogFile'].str.contains('sample4'), 'N'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dual energy mouse is different\n",
    "Data.loc[Data['LogFile'].str.contains('1EAR'), 'Strain'] = 'C57BL/6'\n",
    "Data.loc[Data['LogFile'].str.contains('1EAR'), 'Age'] = '60 weeks'\n",
    "Data.loc[Data['LogFile'].str.contains('1EAR'), 'Sex'] = 'f'\n",
    "Data.loc[Data['LogFile'].str.contains('1EAR'), 'N'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Figure', 'Animal', 'Strain', 'Age', 'Sex', 'N', 'Sample', 'Scanner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out a subset of the columns of the dataframe as a CSV file for adding to the supplementary materials\n",
    "# With renamed column names\n",
    "Data[['Figure', 'Animal', 'Strain', 'Age', 'Sex', 'N',\n",
    "      'Sample', 'Scanner', 'ControlSoftware',\n",
    "      'Voxelsize_rounded', 'Source', 'Voltage', 'Current', 'Filter',\n",
    "      'Camera', 'ProjSize', 'NumProj', 'ThreeSixty', 'RotationStep', 'Averaging', 'Exposure', 'Stacks', 'Wide', 'Duration',\n",
    "      'NRecon', 'RingRemoval', 'Beamhardening', 'LogFile'\n",
    "     ]].to_csv(os.path.join(Root, 'SampleAndScanData.csv'),\n",
    "               index=False,\n",
    "               header=['Figure',\n",
    "                       'Animal', 'Strain', 'Age', 'Sex', 'Number of animals [N]',\n",
    "                       'Sample name', 'Scanner', 'Control software version',\n",
    "                       'Voxelsize [μm]', 'X-ray source', 'Source voltage [kV]', 'Source current [μA]', 'Filter',\n",
    "                       'Detector', 'Projection size [px]', 'Number of Projections', '360°-scan', 'Rotation step [°]', 'Frame averaging', 'Exposure time [ms]', 'Stacked scans', 'Offset positions', 'Scan duration [s]',\n",
    "                       'NRecon version', 'Ring removal correction', 'Beam hardening correction', 'Log file'\n",
    "                     ])\n",
    "# This CSV file is nicely shown online on GitHub at https://github.com/microct-ana-unibe-ch/microvasculature-manuscript/blob/main/content/data/SampleAndScanData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now that we loaded all the relevant data from the log files, we can produce some text.\n",
    "Copy-paste this text into the manuscript and edit accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print relevant data for each figure\n",
    "for figure in Data.Figure.unique():\n",
    "    print(40*'v', figure, 40*'v')\n",
    "    print('The %s scans for Figure %s' % (len(Data[Data.Figure == figure]), figure), end=' ')\n",
    "    print('were performed on a %s:' % Data[Data.Figure == figure].Scanner.unique(), end=' ')\n",
    "    print('with control software version %s.' % Data[Data.Figure == figure].ControlSoftware.unique())\n",
    "    print('The scans are:')\n",
    "    for folder in Data[Data.Figure == figure].Folder:\n",
    "        print('- %s' % folder)\n",
    "    print('The X-ray source was set to a tube voltage of',\n",
    "          \" OR \".join(str(value) for value in Data[Data.Figure == figure].Voltage.unique()),\n",
    "          'kV and a tube current of',\n",
    "          \" OR \".join(str(value) for value in Data[Data.Figure == figure].Current.unique()),\n",
    "          'µA', end='')\n",
    "    if Data[Data.Figure == figure].Filter.unique()[0]:  \n",
    "        print(', the x-ray spectrum was filtered by',\n",
    "              \" OR \".join(str(value) for value in Data[Data.Figure == figure].Filter.unique()),\n",
    "              'prior to incidence onto the sample.')\n",
    "    else:\n",
    "        print('.')\n",
    "    print('For each scan, we acquired %s projections.' % Data[Data.Figure == figure].NumProj.unique(), end=' ')\n",
    "    print('Projection images were recorded over a sample rotation of', end=' ')\n",
    "    if Data[Data.Figure == figure].ThreeSixty.unique():\n",
    "        print('360°', end=', ')\n",
    "    else:\n",
    "        print('180°', end=', ')\n",
    "    print('with one projection acquired at each %s°' % Data[Data.Figure == figure].RotationStep.unique(), end=', ')\n",
    "    print('with %s projections averaged for noise reduction.' % Data[Data.Figure == figure].Averaging.unique())\n",
    "    if len(Data[Data.Figure == figure].Wide.unique()) > 1:\n",
    "        print('%s projections were stitched to cover the full extent of the sample' % Data[Data.Figure == figure].Wide.unique())\n",
    "    else:\n",
    "        if Data[Data.Figure == figure].Wide.unique():\n",
    "            print(Data[Data.Figure == figure].Wide.unique())\n",
    "    print('Each projection image with a size of %s pixels' % Data[Data.Figure == figure].ProjSize.unique(), end= ' ')\n",
    "    if len(Data[Data.Figure == figure].Exposure.unique()) > 1:\n",
    "        print('was exposed for %s ms (on average).' % (round(numpy.mean(Data[Data.Figure == figure].Exposure.unique()))))\n",
    "    else:\n",
    "        print('was exposed for %s ms.' % Data[Data.Figure == figure].Exposure.unique())\n",
    "    print('This resulted in datasets with an isotropic voxel size of %s μm.' % Data[Data.Figure == figure].Voxelsize.unique())\n",
    "    print(40*'^', figure, 40*'^')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
