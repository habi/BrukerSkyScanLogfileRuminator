{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the paragraph about the microCT-scanning from logfiles of the scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are loading all the data from the folder /home/habi/P/Documents/Publications/Ruslan Bone/manubot/content/data\n"
     ]
    }
   ],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "if 'Linux' in platform.system():\n",
    "    BasePath = os.path.join(os.path.sep, 'home', 'habi', 'P')\n",
    "elif 'Windows' in platform.system():\n",
    "    BasePath = os.path.join('P:', os.sep)\n",
    "# Use *this* folder for the bone microvasculature manuscript\n",
    "Root = os.path.join(BasePath, 'Documents', 'Publications', 'Ruslan Bone', 'manubot', 'content', 'data')\n",
    "print('We are loading all the data from the folder %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "# Using os.walk is way faster than using recursive glob.glob, see DataWrangling.ipynb for details\n",
    "# Not sorting the found logfiles is also making it quicker\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 54 log files in /home/habi/P/Documents/Publications/Ruslan Bone/manubot/content/data\n"
     ]
    }
   ],
   "source": [
    "print('We found %s log files in %s' % (len(Data), Root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data from all the log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Scanner'] = [scanner(log) for log in Data['LogFile']]\n",
    "Data['ControlSoftware'] = [controlsoftware(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voxelsize'] = [pixelsize(log) for log in Data['LogFile']]\n",
    "Data['Voxelsize_rounded'] = [pixelsize(log,rounded=True) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Source'] = [source(log) for log in Data['LogFile']]\n",
    "Data['Camera'] = [camera(log) for log in Data['LogFile']]\n",
    "Data['Exposure'] = [exposuretime(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [averaging(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voltage'] = [voltage(log) for log in Data['LogFile']]\n",
    "Data['Current'] = [current(log) for log in Data['LogFile']]\n",
    "Data['Filter'] = [whichfilter(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Stacks'] = [stacks(log) for log in Data['LogFile']]\n",
    "Data['NumProj'] = [numproj(log) for log in Data['LogFile']]\n",
    "Data['ProjSize'] = [projection_size(log) for log in Data['LogFile']]\n",
    "Data['ThreeSixty'] = [threesixtyscan(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [rotationstep(log) for log in Data['LogFile']]\n",
    "Data['Wide'] = [overlapscan(log) for log in Data.LogFile]\n",
    "Data['Duration'] = [duration(log) for log in Data['LogFile']]\n",
    "Data['Date'] = [scandate(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['NRecon'] = [nreconversion(log)[1] for log in Data['LogFile']]\n",
    "Data['RingRemoval'] = [ringremoval(log) for log in Data['LogFile']]\n",
    "Data['Beamhardening'] = [beamhardening(log) for log in Data['LogFile']]\n",
    "Data['DefectPixelMasking'] = [defectpixelmasking(log) for log in Data['LogFile']]\n",
    "Data['GrayValue'] = [reconstruction_grayvalue(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['RecSize'] = [reconstruction_size(log) for log in Data['LogFile']]\n",
    "Data['ROI'] = [region_of_interest(log, verbose=False) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Duration'] = [duration(log) for log in Data['LogFile']]\n",
    "Data['Date'] = [scandate(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we loaded the data, we customize the standard log file parser notebook for the microvasculature manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folder name\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample name to then match to figure number\n",
    "# We bluntly split the path at the `os.path.sep` and user the first item of this separated list\n",
    "Data['Sample'] = [(foldername[len(Root)+1:]).split(os.path.sep)[0] for foldername in Data['Folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_figure(samplename):\n",
    "    figurenumber = None\n",
    "    if 'Israel' in samplename:\n",
    "        figurenumber = 1\n",
    "    elif '11O' in samplename:\n",
    "        # Some are named 11OKT, some 11Okt\n",
    "        figurenumber = 2\n",
    "    elif 'c1m5' in samplename:\n",
    "        figurenumber = 3\n",
    "    elif '0_99' in samplename:\n",
    "        figurenumber = 4    \n",
    "    elif 'Vreni' in samplename:\n",
    "        figurenumber = 5\n",
    "    elif '_sample4' in samplename:\n",
    "        figurenumber = 6\n",
    "    elif 'Mouse_1EAR' in samplename:\n",
    "        figurenumber = 7\n",
    "    return(str(figurenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sample names to our figures \n",
    "Data['Figure'] = [match_to_figure(s) for s in Data['Sample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by figure number\n",
    "Data.sort_values(by=['Figure', 'Sample'], inplace=True)\n",
    "# Reset dataframe index\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cull irrelevant beginning of path from logfile\n",
    "Data['LogFile'] = [lf[len(Root)+1:] for lf in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cull irrelevant beginning of path from logfile\n",
    "Data['Folder'] = [folder.split('data')[1] for folder in Data['Folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogFile</th>\n",
       "      <th>Scanner</th>\n",
       "      <th>Software</th>\n",
       "      <th>Voxelsize</th>\n",
       "      <th>Voxelsize_rounded</th>\n",
       "      <th>Source</th>\n",
       "      <th>Camera</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Averaging</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>...</th>\n",
       "      <th>RecSize</th>\n",
       "      <th>ROI</th>\n",
       "      <th>RecRotation</th>\n",
       "      <th>ControlSoftware</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Date</th>\n",
       "      <th>NRecon</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Figure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET_...</td>\n",
       "      <td>SkyScan 1273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.000382</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Hamamatsu L9181-02</td>\n",
       "      <td>DEXELA-2315[v1], S/N 32960</td>\n",
       "      <td>225</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(4724, 3012)</td>\n",
       "      <td>(4152, 1138, 10, 4734)</td>\n",
       "      <td>-85.59</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14868.0</td>\n",
       "      <td>2019-07-20 14:23:14</td>\n",
       "      <td>1.7.4.2</td>\n",
       "      <td>/Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET...</td>\n",
       "      <td>Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET_</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              LogFile       Scanner Software  \\\n",
       "39  Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET_...  SkyScan 1273      1.1   \n",
       "\n",
       "    Voxelsize  Voxelsize_rounded              Source  \\\n",
       "39   9.000382                9.0  Hamamatsu L9181-02   \n",
       "\n",
       "                        Camera  Exposure  Averaging  Voltage  ...  \\\n",
       "39  DEXELA-2315[v1], S/N 32960       225          5    100.0  ...   \n",
       "\n",
       "         RecSize                     ROI  RecRotation  ControlSoftware  \\\n",
       "39  (4724, 3012)  (4152, 1138, 10, 4734)       -85.59              1.1   \n",
       "\n",
       "   Duration                Date   NRecon  \\\n",
       "39  14868.0 2019-07-20 14:23:14  1.7.4.2   \n",
       "\n",
       "                                               Folder  \\\n",
       "39  /Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET...   \n",
       "\n",
       "                                            Sample  Figure  \n",
       "39  Vreni_Jaw_Jul19_AL1mm-Cu02mm_100kV_9um_OFFSET_       5  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out relevant columns of the dataframe as csv for adding to the supplementary materials\n",
    "# With renamed column names\n",
    "Data[['Figure', 'Sample', 'Scanner', 'ControlSoftware', 'Date',\n",
    "      'Voxelsize_rounded', 'Source', 'Voltage', 'Current', 'Filter', 'ProjSize', 'ThreeSixty', 'RotationStep',\n",
    "      'Averaging', 'Exposure', 'Stacks', 'Wide', 'Duration',\n",
    "      'NRecon', 'RingRemoval', 'Beamhardening', 'LogFile'\n",
    "     ]].to_csv(os.path.join(Root, 'ScanningDetails.csv'),\n",
    "               index=False,\n",
    "               header=['Figure', 'Sample name', 'Scanner', 'Control software version', 'Scan date',\n",
    "                       'Voxelsize [μm]', 'X-ray source', 'Source voltage [kV]', 'Source current [μA]',\n",
    "                       'Filter', 'Projection size', '360°-scan', 'Rotation step [°]', 'Frame averaging',\n",
    "                       'Exposure time [ms]', 'Stacked scans', 'Overlap scans',\n",
    "                       'Scan duration [s]',\n",
    "                       'NRecon version', 'Ring removal correction', 'Beam hardening correction',\n",
    "                       'Log file'\n",
    "                     ])\n",
    "# This csv file is nicely shown online on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out as .xlsx sheet, too\n",
    "# This Excel sheet is not uploaded to Github, but makes it easy to quickly look at it\n",
    "Data[['Figure', 'Sample', 'Scanner', 'ControlSoftware', 'Date',\n",
    "      'Voxelsize_rounded', 'Source', 'Voltage', 'Current', 'Filter', 'ProjSize', 'ThreeSixty', 'RotationStep',\n",
    "      'Averaging', 'Exposure', 'Stacks', 'Wide', 'Duration',\n",
    "      'NRecon', 'RingRemoval', 'Beamhardening', 'LogFile'\n",
    "     ]].to_excel(os.path.join(Root, 'ScanningDetails.xlsx'),\n",
    "               index=False,\n",
    "               header=['Figure', 'Sample name', 'Scanner', 'Control software version', 'Scan date',\n",
    "                       'Voxelsize [μm]', 'X-ray source', 'Source voltage [kV]', 'Source current [μA]',\n",
    "                       'Filter', 'Projection size', '360°-scan', 'Rotation step [°]', 'Frame averaging',\n",
    "                       'Exposure time [ms]', 'Stacked scans', 'Overlap scans',\n",
    "                       'Scan duration [s]',\n",
    "                       'NRecon version', 'Ring removal correction', 'Beam hardening correction',\n",
    "                       'Log file'\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text in the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for figure in Data.Figure.unique():\n",
    "    print(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.Current.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.Filter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.Filter.unique().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The X-ray source was set to a tube voltage of', \n",
    "      \" OR \".join(str(value) for value in Data.Voltage.unique()),\n",
    "      'kV and a tube current of',\n",
    "      \" OR \".join(str(value) for value in Data.Current.unique()),\n",
    "      'µA, the x-ray spectrum was', end=' ')\n",
    "if Data.Filter.unique().any():\n",
    "    print('filtered by', \" OR \".join(str(value) for value in Data.Filter.unique()), end=' ')\n",
    "else:\n",
    "    print('not filtered', end=' ')\n",
    "print('prior to incidence onto the sample.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Flip the text of the filter to make it nicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Wide.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.ProjSize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.ThreeSixty.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('For each sample, we recorded a set of', end=' ')\n",
    "if Data.Filter.unique().tolist():   \n",
    "    print(\" or \".join(str(value) for value in Data.Stacks.unique()),\n",
    "          'stacked scans overlapping the sample height, each stack was recorded with', end=' ')\n",
    "print(\" or \".join(str(value) for value in Data.NumProj.unique()), 'projections of', end=' ')\n",
    "for cs in Data.ProjSize.unique():\n",
    "    print(cs[0], end=' ')\n",
    "print('x', end=' ')\n",
    "for cs in Data.ProjSize.unique():\n",
    "    print(cs[1], end=' ')\n",
    "print('pixels', end=' ')\n",
    "if Data.Wide.unique().tolist():\n",
    "    print('(' + \" or \".join(str(value) for value in Data.Wide.unique()), 'projections stitched laterally)', end=' ')\n",
    "print('at every',\n",
    "       str(\" or \".join(str(value) for value in Data.RotationStep.unique())) + '° over a ', end='')\n",
    "if Data.ThreeSixty.unique().tolist():\n",
    "     print('360°', end=' ')\n",
    "else:\n",
    "    print('180°', end=' ')\n",
    "print('sample rotation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Exposure.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Every single projection was exposed for',\n",
    "      \" or \".join(str(value) for value in Data.Exposure.unique()),\n",
    "      'ms,',\n",
    "      \" or \".join(str(value) for value in Data.Averaging.unique()),\n",
    "      'projections were averaged to one to greatly reduce image noise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log=Data.LogFile.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the cell below, we exclude all subscan logfiles\n",
    "# These do *not* contain any information on NRecon\n",
    "# From this subset, we select 1 logfile and work with that\n",
    "log = Data[~ Data['LogFile'].str.contains('~')].sample(n=1).LogFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log = log[log.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.path.basename(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This resulted in a scan time of approximately ', end='')\n",
    "if duration(log)/3600 > 1:\n",
    "    # Scan took hours\n",
    "    print(timeformat(datetime.timedelta(seconds=duration(log)),\n",
    "                     '{hours} hours and {minutes} minutes'), end=' ')\n",
    "else:\n",
    "    print(timeformat(datetime.timedelta(seconds=duration(log)),\n",
    "                     '{minutes} minutes'), end=' ')\n",
    "if not stacks(log) == 1:\n",
    "    print('per stack and about',\n",
    "          timeformat(stacks(log) * datetime.timedelta(seconds=duration(log)),\n",
    "                     '{hours} hours and {minutes} minutes'), end=' ')\n",
    "print('per sample', end='')\n",
    "if stacks(log) == 1:\n",
    "    print('.')\n",
    "else:\n",
    "    print(' (with', stacks(log), 'stacks).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, we scanned', Data.Stacks.sum(), 'stacks.')\n",
    "print('Each stack took approximately',\n",
    "      Data.Duration.mean() // 60,\n",
    "      'minutes (' + str(datetime.timedelta(seconds=Data.Duration.mean())) + ')')\n",
    "print('In total, we thus scanned for about', \n",
    "      timeformat(Data.Stacks.sum() *\n",
    "                 datetime.timedelta(seconds=Data.Duration.mean()),\n",
    "                 '{days} days, {hours} hours and {minutes} minutes.'))\n",
    "hourlyrate = 125\n",
    "print('At the MIC rate of %s CHF/h, this would have cost %s CHF' % (\n",
    "    hourlyrate,\n",
    "    int(round(Data.Stacks.sum() * Data.Duration.mean() / 60 / 60 * hourlyrate))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Voxelsize.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Beamhardening.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The projection images were then subsequently reconstructed into a 3D stack',\n",
    "      'of images with',\n",
    "      Data.Version.unique()[0][0],\n",
    "      '(Version',\n",
    "      nreconversion(log)[1] + ', Bruker microCT, Kontich Belgium)', end=' ')\n",
    "if ringremoval(log):\n",
    "    print('using a ring artifact correction of',\n",
    "          ringremoval(log), end='')\n",
    "if beamhardening(log):\n",
    "    print(' and a beam hardening correction of',\n",
    "          beamhardening(log),\n",
    "          '%.')\n",
    "else:\n",
    "    print('.')\n",
    "print('The whole process resulted in datasets with an isometric voxel size of',\n",
    "      \" or \".join(str(value) for value in Data.Voxelsize_rounded.unique()),\n",
    "      'µm.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
