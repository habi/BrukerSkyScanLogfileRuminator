{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the paragraph about the microCT-scanning from logfiles of the scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "if 'Linux' in platform.system():\n",
    "    BasePath = os.path.join(os.path.sep, 'home', 'habi', 'research_storage_uct', 'Archiv_Tape')\n",
    "elif 'Windows' in platform.system():\n",
    "    BasePath = os.path.join('R:', os.sep)\n",
    "Root = os.path.join(BasePath, 'Fernandez Melanoma')\n",
    "print('We are loading all the data from the folder %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "# Using os.walk is way faster than using recursive glob.glob, see DataWrangling.ipynb for details\n",
    "# Not sorting the found logfiles is also making it quicker\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder names\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See what we get\n",
    "Data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We found in total %s log files in %s, let us now look at them' % (len(Data), Root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all the logfiles from all the folders that might be on disk but that we don't want to load the data from\n",
    "for c, row in Data.iterrows():\n",
    "    if 'SubScan' in row.Folder:  # Prematurely synchronized folders might be present\n",
    "        print('Dropping', row.LogFile, 'as we are not interested in it')\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'batman' in row.LogFile: # There's nothing interesting in the Bruker batch manager log files\n",
    "        Data.drop([c], inplace=True)\n",
    "        print('Dropping', row.LogFile, 'as we are not interested in it')\n",
    "    elif 'ctan.log' in row.LogFile: # There's nothing interesting in the Bruker CT Analzyer log files\n",
    "        Data.drop([c], inplace=True)\n",
    "        print('Dropping', row.LogFile, 'as we are not interested in it')\n",
    "    elif 'rectmp.log' in row.LogFile: # Prematurely synchronized files might be present\n",
    "        Data.drop([c], inplace=True)\n",
    "        print('Dropping', row.LogFile, 'as we are not interested in it')\n",
    "    elif os.path.basename(row.LogFile).startswith('._'): # Someone on macOS might have looked at the files\n",
    "        Data.drop([c], inplace=True)\n",
    "        print('Dropping', row.LogFile, 'as we are not interested in it')        \n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After cleanup, we now have a total of %s log files to look at' % len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Scanner'] = [scanner(log) for log in Data['LogFile']]\n",
    "Data['Software'] = [controlsoftware(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voxelsize'] = [pixelsize(log) for log in Data['LogFile']]\n",
    "Data['Voxelsize_rounded'] = [pixelsize(log,rounded=True) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Source'] = [source(log) for log in Data['LogFile']]\n",
    "Data['Camera'] = [camera(log) for log in Data['LogFile']]\n",
    "Data['Exposure'] = [exposuretime(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [averaging(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voltage'] = [voltage(log) for log in Data['LogFile']]\n",
    "Data['Current'] = [current(log) for log in Data['LogFile']]\n",
    "Data['Filter'] = [whichfilter(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Stacks'] = [stacks(log) for log in Data['LogFile']]\n",
    "Data['NumProj'] = [numproj(log) for log in Data['LogFile']]\n",
    "Data['ProjSize'] = [projection_size(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [rotationstep(log) for log in Data['LogFile']]\n",
    "Data['Wide'] = [overlapscan(log) for log in Data.LogFile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Version'] = [nreconversion(log) for log in Data['LogFile']]\n",
    "Data['RingRemoval'] = [ringremoval(log) for log in Data['LogFile']]\n",
    "Data['Beamhardening'] = [beamhardening(log) for log in Data['LogFile']]\n",
    "Data['DefectPixelMasking'] = [defectpixelmasking(log) for log in Data['LogFile']]\n",
    "Data['GrayValue'] = [reconstruction_grayvalue(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['RecSize'] = [reconstruction_size(log) for log in Data['LogFile']]\n",
    "Data['ROI'] = [region_of_interest(log, verbose=False) for log in Data['LogFile']]\n",
    "Data['RecRotation'] = [crosssection_rotation(log, verbose=False) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Duration'] = [duration(log) for log in Data['LogFile']]\n",
    "Data['Date'] = [scandate(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by scan date\n",
    "Data.sort_values(by='Date', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv('ScanningDetails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My microct blurb from http://simp.ly/publish/NBhZhH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cris mentioned that he used the scans \"D [...] for [...] Figure 2\".\n",
    "Let's make us a subset of the dataframe for adding the text into the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only look at the scans of the 'D' samples\n",
    "Data_Figure2 = Data[Data['LogFile'].str.contains('D')]\n",
    "# Get rid of the irrelevant sample \"646L_Dry\"\n",
    "Data_Figure2 = Data_Figure2.drop(Data_Figure2[Data_Figure2['LogFile'].str.contains('646L')].index)\n",
    "# Drop all *rec* log files\n",
    "Data_Figure2 = Data_Figure2.drop(Data_Figure2[Data_Figure2['LogFile'].str.contains('rec')].index)\n",
    "# Drop all subscan log files\n",
    "Data_Figure2 = Data_Figure2.drop(Data_Figure2[Data_Figure2['LogFile'].str.contains('~')].index)\n",
    "# Drop the four scans done on the 2214, which were not used for Figure 2\n",
    "Data_Figure2 = Data_Figure2.drop(Data_Figure2[Data_Figure2['Scanner'].str.contains('2214')].index)\n",
    "# Drop one scan that was scanned 'too_high'\n",
    "Data_Figure2 = Data_Figure2.drop(Data_Figure2[Data_Figure2['LogFile'].str.contains('too')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Based on the %s log files containing a \"D\" in their name' % len(Data_Figure2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we have now?\n",
    "Data_Figure2.LogFile.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After $PREPARATION, the',\n",
    "      len(Data_Figure2),\n",
    "      'samples were imaged on a Bruker',\n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Scanner.unique()),\n",
    "      'high-resolution microtomography machine (Control software version',\n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Software.unique()) + \n",
    "      ', Bruker microCT, Kontich, Belgium).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The machine is equipped with a',\n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Source.unique()),\n",
    "      'X-ray source and a',\n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Camera.unique()),\n",
    "      'camera.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The X-ray source was set to a tube voltage of', \n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Voltage.unique()),\n",
    "      'kV and a tube current of',\n",
    "      \" OR \".join(str(value) for value in Data_Figure2.Current.unique()),\n",
    "      'µA, the x-ray spectrum was', end=' ')\n",
    "if Data_Figure2.Filter.unique():\n",
    "    print('filtered by', \" OR \".join(str(value) for value in Data_Figure2.Filter.unique()), end=' ')\n",
    "else:\n",
    "    print('not filtered', end=' ')\n",
    "print('prior to incidence onto the sample.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For each sample, we recorded a set of', end=' ')\n",
    "if Data_Figure2.Filter.unique():   \n",
    "    print(\" or \".join(str(value) for value in Data_Figure2.Stacks.unique()),\n",
    "          'stacked scans overlapping the sample height, each stack was recorded with', end=' ')\n",
    "print(\" or \".join(str(value) for value in Data_Figure2.NumProj.unique()), 'projections with a size of', end=' ')\n",
    "for cs in Data_Figure2.ProjSize.unique():\n",
    "    print(cs[0], end=' ')\n",
    "print('x', end=' ')\n",
    "for cs in Data_Figure2.ProjSize.unique():\n",
    "    print(cs[1], end=' ')\n",
    "print('pixels each', end=' ')\n",
    "if Data_Figure2.Wide.unique():\n",
    "    print('(' + \" or \".join(str(value) for value in Data_Figure2.Wide.unique()), 'projections stitched laterally)', end=' ')\n",
    "print('at every',\n",
    "      str(\" or \".join(str(value) for value in Data_Figure2.RotationStep.unique())) + '° over a 180° sample rotation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Figure2.Exposure.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Every single projection was exposed for',\n",
    "      \" or \".join(str(value) for value in Data_Figure2.Exposure.unique()),\n",
    "      'ms,',\n",
    "      \" or \".join(str(value) for value in Data_Figure2.Averaging.unique()),\n",
    "      'projections were averaged to one to greatly reduce image noise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Figure2.Duration.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeformat(tdelta, fmt):\n",
    "    # From https://stackoverflow.com/a/8907269/323100\n",
    "    d = {\"days\": tdelta.days}\n",
    "    d[\"hours\"], rem = divmod(tdelta.seconds, 3600)\n",
    "    d[\"minutes\"], d[\"seconds\"] = divmod(rem, 60)\n",
    "    return fmt.format(**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This resulted in a scan time of approximately ', end='')\n",
    "print(timeformat(datetime.timedelta(seconds=Data_Figure2.Duration.mean()),\n",
    "                     '{hours} hours and {minutes} minutes'), end=' ')\n",
    "print('per sample (with %s stack per sample))' % Data_Figure2.Stacks.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, we scanned', Data_Figure2.Stacks.sum(), 'stacks.')\n",
    "print('Each stack took approximately',\n",
    "      Data_Figure2.Duration.mean() // 60,\n",
    "      'minutes (' + str(datetime.timedelta(seconds=Data_Figure2.Duration.mean())) + ')')\n",
    "print('In total, we thus scanned for about', \n",
    "      timeformat(Data_Figure2.Stacks.sum() *\n",
    "                 datetime.timedelta(seconds=Data_Figure2.Duration.mean()),\n",
    "                 '{days} days, {hours} hours and {minutes} minutes.'))\n",
    "print('At the MIC rate, this would have cost',\n",
    "      int(round(Data_Figure2.Stacks.sum() * Data_Figure2.Duration.mean() / 60 / 60 * 75)),\n",
    "      'CHF.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The projection images were then subsequently reconstructed into a 3D stack',\n",
    "      'of images with',\n",
    "      Data_Figure2.Version.unique()[0][0],\n",
    "      '(Version',\n",
    "      nreconversion(log)[1] + ', Bruker microCT, Kontich Belgium)', end=' ')\n",
    "if ringremoval(log):\n",
    "    print('using a ring artifact correction of',\n",
    "          ringremoval(log), end='')\n",
    "if beamhardening(log):\n",
    "    print(' and a beam hardening correction of',\n",
    "          beamhardening(log),\n",
    "          '%.')\n",
    "else:\n",
    "    print('.')\n",
    "print('The whole process resulted in datasets with an isometric voxel size of',\n",
    "      \" or \".join(str(value) for value in Data_Figure2.Voxelsize_rounded.unique()),\n",
    "      'µm.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulllog(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Figure2.Voxelsize.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Figure2.Beamhardening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
